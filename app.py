import streamlit as st
from langchain.document_loaders import PyPDFLoader, TextLoader, UnstructuredHTMLLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.chains import ConversationalRetrievalChain
from langchain.chat_models import ChatOpenAI
from pathlib import Path
import glob
import os

st.set_page_config(page_title="AI Onboarding Chat", layout="wide")
st.title("üí¨ AI-alap√∫ Onboarding Chat Asszisztens")

# OpenAI API kulcs
OPENAI_API_KEY = st.secrets.get("OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    st.warning("‚ö†Ô∏è Add meg az OpenAI API kulcsot a m≈±k√∂d√©shez.")
    st.stop()

# Session state a besz√©lget√©shez
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# Dokumentumok bet√∂lt√©se h√°tt√©rb≈ël
DOCUMENT_DIR = "documents/"  # Ebbe a mapp√°ba t√∂ltsd a f√°jlokat manu√°lisan
if not os.path.exists(DOCUMENT_DIR):
    st.warning(f"‚ö†Ô∏è A '{DOCUMENT_DIR}' mappa nem tal√°lhat√≥. Hozd l√©tre √©s t√∂lts bele f√°jlokat.")
    st.stop()

documents = []
for filepath in glob.glob(f"{DOCUMENT_DIR}/*"):
    path = Path(filepath)
    if path.suffix == ".pdf":
        loader = PyPDFLoader(str(path))
    elif path.suffix == ".txt":
        loader = TextLoader(str(path))
    elif path.suffix == ".html":
        loader = UnstructuredHTMLLoader(str(path))
    else:
        continue
    documents.extend(loader.load())

if documents:
    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    chunks = splitter.split_documents(documents)
    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
    db = FAISS.from_documents(chunks, embeddings)
    retriever = db.as_retriever()
    qa_chain = ConversationalRetrievalChain.from_llm(
        llm=ChatOpenAI(openai_api_key=OPENAI_API_KEY),
        retriever=retriever
    )

    user_input = st.chat_input("√çrd be a k√©rd√©sed...")

    if user_input:
        with st.spinner("Gondolkodom a v√°laszon..."):
            result = qa_chain.run({"question": user_input, "chat_history": st.session_state.chat_history})
        st.session_state.chat_history.append((user_input, result))

    for i, (q, a) in enumerate(reversed(st.session_state.chat_history)):
        st.chat_message("user", avatar="üë§").write(q)
        st.chat_message("assistant", avatar="ü§ñ").write(a)
else:
    st.info("üìÇ T√∂lts fel f√°jlokat a 'documents/' mapp√°ba, hogy a rendszer v√°laszolni tudjon a k√©rd√©sekre.")
